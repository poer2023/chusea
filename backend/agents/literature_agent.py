from typing import Dict, Any, List, Optional
import requests
import json
from datetime import datetime
from core.agent_manager import BaseAgent, AgentType, AgentRequest, AgentResponse
from core.llm_client import LLMClientFactory
from dataclasses import dataclass

@dataclass
class LiteratureItem:
    title: str
    authors: List[str]
    year: int
    doi: Optional[str] = None
    abstract: Optional[str] = None
    source: str = ""
    url: Optional[str] = None
    citation_count: int = 0
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            "title": self.title,
            "authors": self.authors,
            "year": self.year,
            "doi": self.doi,
            "abstract": self.abstract,
            "source": self.source,
            "url": self.url,
            "citation_count": self.citation_count
        }

class LiteratureSearcher:
    """æ–‡çŒ®æœç´¢å™¨åŸºç±»"""
    
    async def search(self, query: str, max_results: int = 10) -> List[LiteratureItem]:
        raise NotImplementedError

class SemanticScholarSearcher(LiteratureSearcher):
    """Semantic Scholar APIæœç´¢å™¨ï¼ˆå…è´¹ï¼‰"""
    
    def __init__(self):
        self.base_url = "https://api.semanticscholar.org/graph/v1"
    
    async def search(self, query: str, max_results: int = 10) -> List[LiteratureItem]:
        try:
            # æœç´¢è®ºæ–‡
            search_url = f"{self.base_url}/paper/search"
            params = {
                "query": query,
                "limit": max_results,
                "fields": "title,authors,year,abstract,citationCount,externalIds,url"
            }
            
            response = requests.get(search_url, params=params, timeout=10)
            response.raise_for_status()
            
            data = response.json()
            literature_items = []
            
            for paper in data.get("data", []):
                authors = [author.get("name", "") for author in paper.get("authors", [])]
                
                # èŽ·å–DOI
                doi = None
                external_ids = paper.get("externalIds", {})
                if external_ids and "DOI" in external_ids:
                    doi = external_ids["DOI"]
                
                item = LiteratureItem(
                    title=paper.get("title", ""),
                    authors=authors,
                    year=paper.get("year", 0) or 0,
                    doi=doi,
                    abstract=paper.get("abstract", ""),
                    source="Semantic Scholar",
                    url=paper.get("url", ""),
                    citation_count=paper.get("citationCount", 0) or 0
                )
                literature_items.append(item)
            
            return literature_items
            
        except Exception as e:
            print(f"Semantic Scholar search error: {e}")
            return []

class ArxivSearcher(LiteratureSearcher):
    """ArXiv APIæœç´¢å™¨ï¼ˆå…è´¹ï¼‰"""
    
    def __init__(self):
        self.base_url = "http://export.arxiv.org/api/query"
    
    async def search(self, query: str, max_results: int = 10) -> List[LiteratureItem]:
        try:
            params = {
                "search_query": f"all:{query}",
                "start": 0,
                "max_results": max_results
            }
            
            response = requests.get(self.base_url, params=params, timeout=10)
            response.raise_for_status()
            
            # è§£æžXMLå“åº”
            import xml.etree.ElementTree as ET
            root = ET.fromstring(response.content)
            
            literature_items = []
            
            for entry in root.findall("{http://www.w3.org/2005/Atom}entry"):
                title = entry.find("{http://www.w3.org/2005/Atom}title").text.strip()
                
                authors = []
                for author in entry.findall("{http://www.w3.org/2005/Atom}author"):
                    name = author.find("{http://www.w3.org/2005/Atom}name").text
                    authors.append(name)
                
                published = entry.find("{http://www.w3.org/2005/Atom}published").text
                year = int(published[:4])
                
                summary = entry.find("{http://www.w3.org/2005/Atom}summary").text.strip()
                
                # èŽ·å–ArXiv ID
                arxiv_id = entry.find("{http://www.w3.org/2005/Atom}id").text.split("/")[-1]
                
                item = LiteratureItem(
                    title=title,
                    authors=authors,
                    year=year,
                    abstract=summary,
                    source="ArXiv",
                    url=f"https://arxiv.org/abs/{arxiv_id}"
                )
                literature_items.append(item)
            
            return literature_items
            
        except Exception as e:
            print(f"ArXiv search error: {e}")
            return []

class LiteratureAgent(BaseAgent):
    def __init__(self):
        super().__init__("LiteratureAgent", AgentType.LITERATURE)
        try:
            self.llm_client = LLMClientFactory.get_default_client()
        except ValueError:
            # å¦‚æžœæ²¡æœ‰é…ç½®LLM APIå¯†é’¥ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼
            self.llm_client = None
        
        # åˆå§‹åŒ–æœç´¢å™¨
        self.searchers = {
            "semantic_scholar": SemanticScholarSearcher(),
            "arxiv": ArxivSearcher()
        }
        
        self.system_prompt = """
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ–‡çŒ®ç®¡ç†åŠ©æ‰‹ã€‚ä½ çš„ä»»åŠ¡æ˜¯å¸®åŠ©ç”¨æˆ·æœç´¢ã€ç®¡ç†å’Œå¼•ç”¨å­¦æœ¯æ–‡çŒ®ã€‚

ä½ å¯ä»¥ï¼š
1. æ ¹æ®å…³é”®è¯æœç´¢ç›¸å…³æ–‡çŒ®
2. åˆ†æžæ–‡çŒ®çš„ç›¸å…³æ€§å’Œè´¨é‡
3. ç”Ÿæˆæ ‡å‡†æ ¼å¼çš„å¼•ç”¨
4. æä¾›æ–‡çŒ®æ‘˜è¦å’Œè§£è¯»
5. å»ºè®®ç›¸å…³çš„ç ”ç©¶æ–¹å‘

è¯·å§‹ç»ˆä¿æŒä¸“ä¸šã€å‡†ç¡®ï¼Œå¹¶æä¾›æœ‰ä»·å€¼çš„æ–‡çŒ®ä¿¡æ¯ã€‚
"""
    
    async def process(self, request: AgentRequest) -> AgentResponse:
        try:
            action = request.context.get("action", "search")
            
            if action == "search":
                return await self._handle_search(request)
            elif action == "cite":
                return await self._handle_citation(request)
            elif action == "analyze":
                return await self._handle_analysis(request)
            else:
                return AgentResponse(
                    content="æœªçŸ¥çš„æ“ä½œç±»åž‹",
                    agent_type=self.agent_type,
                    success=False,
                    error="Unknown action type"
                )
                
        except Exception as e:
            return AgentResponse(
                content="",
                agent_type=self.agent_type,
                success=False,
                error=str(e)
            )
    
    async def _handle_search(self, request: AgentRequest) -> AgentResponse:
        """å¤„ç†æ–‡çŒ®æœç´¢è¯·æ±‚"""
        query = request.prompt
        max_results = request.context.get("max_results", 10)
        source = request.context.get("source", "semantic_scholar")
        
        if source not in self.searchers:
            source = "semantic_scholar"
        
        # æœç´¢æ–‡çŒ®
        searcher = self.searchers[source]
        literature_items = await searcher.search(query, max_results)
        
        if not literature_items:
            return AgentResponse(
                content="æœªæ‰¾åˆ°ç›¸å…³æ–‡çŒ®",
                agent_type=self.agent_type,
                success=True,
                metadata={"search_query": query, "results_count": 0}
            )
        
        # ä½¿ç”¨LLMç”Ÿæˆæœç´¢ç»“æžœæ‘˜è¦ï¼Œå¦‚æžœæ²¡æœ‰LLMåˆ™ç”Ÿæˆæ¨¡æ‹Ÿæ‘˜è¦
        if self.llm_client is None:
            search_summary = self._generate_mock_search_summary(query, literature_items)
        else:
            try:
                search_summary = await self._generate_search_summary(query, literature_items)
            except Exception as llm_error:
                print(f"LLM call failed for literature search, falling back to mock: {llm_error}")
                search_summary = self._generate_mock_search_summary(query, literature_items)
        
        return AgentResponse(
            content=search_summary,
            agent_type=self.agent_type,
            success=True,
            metadata={
                "search_query": query,
                "results_count": len(literature_items),
                "literature_items": [item.to_dict() for item in literature_items]
            }
        )
    
    async def _handle_citation(self, request: AgentRequest) -> AgentResponse:
        """å¤„ç†å¼•ç”¨ç”Ÿæˆè¯·æ±‚"""
        literature_data = request.context.get("literature_data")
        citation_style = request.context.get("style", "APA")
        
        if not literature_data:
            return AgentResponse(
                content="ç¼ºå°‘æ–‡çŒ®æ•°æ®",
                agent_type=self.agent_type,
                success=False,
                error="Missing literature data"
            )
        
        # ç”Ÿæˆå¼•ç”¨
        citation = self._generate_citation(literature_data, citation_style)
        
        return AgentResponse(
            content=citation,
            agent_type=self.agent_type,
            success=True,
            metadata={
                "citation_style": citation_style,
                "literature_data": literature_data
            }
        )
    
    async def _handle_analysis(self, request: AgentRequest) -> AgentResponse:
        """å¤„ç†æ–‡çŒ®åˆ†æžè¯·æ±‚"""
        literature_items = request.context.get("literature_items", [])
        analysis_type = request.context.get("analysis_type", "relevance")
        
        if not literature_items:
            return AgentResponse(
                content="ç¼ºå°‘æ–‡çŒ®æ•°æ®è¿›è¡Œåˆ†æž",
                agent_type=self.agent_type,
                success=False,
                error="Missing literature data for analysis"
            )
        
        # ä½¿ç”¨LLMè¿›è¡Œæ–‡çŒ®åˆ†æžï¼Œå¦‚æžœæ²¡æœ‰LLMåˆ™ç”Ÿæˆæ¨¡æ‹Ÿåˆ†æž
        if self.llm_client is None:
            analysis_content = self._generate_mock_analysis(request.prompt, literature_items, analysis_type)
            return AgentResponse(
                content=analysis_content,
                agent_type=self.agent_type,
                success=True,
                metadata={
                    "analysis_type": analysis_type,
                    "literature_count": len(literature_items),
                    "mock_response": True
                },
                tokens_used=0
            )
        else:
            # ä½¿ç”¨LLMè¿›è¡Œæ–‡çŒ®åˆ†æž
            analysis_prompt = f"""
è¯·å¯¹ä»¥ä¸‹æ–‡çŒ®è¿›è¡Œ{analysis_type}åˆ†æžï¼š

ç”¨æˆ·æŸ¥è¯¢ï¼š{request.prompt}

æ–‡çŒ®åˆ—è¡¨ï¼š
{json.dumps(literature_items, ensure_ascii=False, indent=2)}

è¯·æä¾›ä¸“ä¸šçš„åˆ†æžæ„è§ï¼ŒåŒ…æ‹¬ï¼š
1. æ–‡çŒ®çš„ç›¸å…³æ€§è¯„ä¼°
2. ç ”ç©¶è´¨é‡å’Œå½±å“åŠ›åˆ†æž
3. ä¸»è¦å‘çŽ°å’Œè´¡çŒ®
4. å»ºè®®é˜…è¯»é¡ºåº
"""
            
            llm_response = await self.llm_client.generate(
                prompt=analysis_prompt,
                system_prompt=self.system_prompt
            )
            
            return AgentResponse(
                content=llm_response.content,
                agent_type=self.agent_type,
                success=True,
                metadata={
                    "analysis_type": analysis_type,
                    "literature_count": len(literature_items)
                },
                tokens_used=llm_response.tokens_used
            )
    
    async def _generate_search_summary(self, query: str, literature_items: List[LiteratureItem]) -> str:
        """ç”Ÿæˆæœç´¢ç»“æžœæ‘˜è¦"""
        items_summary = []
        for i, item in enumerate(literature_items[:5], 1):
            authors_str = ", ".join(item.authors[:3])
            if len(item.authors) > 3:
                authors_str += " et al."
            
            items_summary.append(f"{i}. {item.title} ({authors_str}, {item.year})")
        
        prompt = f"""
ç”¨æˆ·æœç´¢æŸ¥è¯¢ï¼š{query}
æ‰¾åˆ° {len(literature_items)} ç¯‡ç›¸å…³æ–‡çŒ®ã€‚

å‰5ç¯‡æ–‡çŒ®ï¼š
{chr(10).join(items_summary)}

è¯·ç”Ÿæˆä¸€ä¸ªç®€æ´çš„æœç´¢ç»“æžœæ‘˜è¦ï¼ŒåŒ…æ‹¬ï¼š
1. æœç´¢ç»“æžœçš„æ€»ä½“æ¦‚è¿°
2. ä¸»è¦ç ”ç©¶æ–¹å‘å’Œä¸»é¢˜
3. æ–‡çŒ®çš„æ—¶é—´åˆ†å¸ƒå’Œè´¨é‡
4. æŽ¨èé˜…è¯»å»ºè®®
"""
        
        llm_response = await self.llm_client.generate(
            prompt=prompt,
            system_prompt=self.system_prompt
        )
        
        return llm_response.content
    
    def _generate_mock_search_summary(self, query: str, literature_items: List[LiteratureItem]) -> str:
        """ç”Ÿæˆæ¨¡æ‹Ÿæœç´¢ç»“æžœæ‘˜è¦"""
        total_count = len(literature_items)
        
        # ç»Ÿè®¡å¹´ä»½åˆ†å¸ƒ
        years = [item.year for item in literature_items if item.year > 0]
        year_range = f"{min(years)}-{max(years)}" if years else "æœªçŸ¥"
        
        # ç»Ÿè®¡æ¥æºåˆ†å¸ƒ
        sources = {}
        for item in literature_items:
            sources[item.source] = sources.get(item.source, 0) + 1
        
        source_info = ", ".join([f"{source}: {count}ç¯‡" for source, count in sources.items()])
        
        return f"""ðŸ“š æ–‡çŒ®æœç´¢ç»“æžœæ‘˜è¦

ðŸ” **æœç´¢æŸ¥è¯¢**: {query}
ðŸ“Š **ç»“æžœæ€»æ•°**: æ‰¾åˆ° {total_count} ç¯‡ç›¸å…³æ–‡çŒ®

ðŸ“ˆ **æ—¶é—´åˆ†å¸ƒ**: {year_range}
ðŸ—‚ï¸ **æ¥æºåˆ†å¸ƒ**: {source_info}

ðŸ’¡ **ä¸»è¦å‘çŽ°**:
â€¢ æœç´¢ç»“æžœæ¶µç›–äº†è¯¥é¢†åŸŸçš„æ ¸å¿ƒç ”ç©¶
â€¢ æ–‡çŒ®è´¨é‡è¾ƒé«˜ï¼Œå¤šæ•°æ¥è‡ªçŸ¥åå­¦æœ¯å¹³å°
â€¢ ç ”ç©¶æ—¶é—´è·¨åº¦é€‚ä¸­ï¼ŒåŒ…å«æœ€æ–°è¿›å±•

ðŸ“– **é˜…è¯»å»ºè®®**:
1. ä¼˜å…ˆé˜…è¯»å¼•ç”¨æ¬¡æ•°é«˜çš„ç»å…¸æ–‡çŒ®
2. å…³æ³¨è¿‘å¹´æ¥çš„æœ€æ–°ç ”ç©¶è¿›å±•
3. ç»“åˆä¸åŒæ¥æºçš„æ–‡çŒ®èŽ·å¾—å…¨é¢è§†è§’

ðŸ’¡ æç¤º: è¿™æ˜¯æ¼”ç¤ºæ¨¡å¼çš„æœç´¢æ‘˜è¦ã€‚é…ç½®LLM APIå¯†é’¥åŽå¯èŽ·å¾—æ›´è¯¦ç»†çš„æ™ºèƒ½åˆ†æžã€‚"""

    def _generate_mock_analysis(self, query: str, literature_items: List[Dict], analysis_type: str) -> str:
        """ç”Ÿæˆæ¨¡æ‹Ÿæ–‡çŒ®åˆ†æž"""
        count = len(literature_items)
        
        if analysis_type == "relevance":
            return f"""ðŸŽ¯ æ–‡çŒ®ç›¸å…³æ€§åˆ†æž

ðŸ“ **åˆ†æžæŸ¥è¯¢**: {query}
ðŸ“š **æ–‡çŒ®æ•°é‡**: {count} ç¯‡

ðŸ” **ç›¸å…³æ€§è¯„ä¼°**:
â€¢ é«˜åº¦ç›¸å…³: {max(1, count//3)} ç¯‡ - ç›´æŽ¥å›žåº”ç ”ç©¶é—®é¢˜
â€¢ ä¸­åº¦ç›¸å…³: {max(1, count//2)} ç¯‡ - æä¾›èƒŒæ™¯å’Œæ”¯æ’‘
â€¢ ä½Žåº¦ç›¸å…³: {count - max(1, count//3) - max(1, count//2)} ç¯‡ - æ‰©å±•é˜…è¯»ä»·å€¼

â­ **è´¨é‡è¯„ä¼°**:
â€¢ æ‰€é€‰æ–‡çŒ®å‡æ¥è‡ªå¯ä¿¡å­¦æœ¯æ¥æº
â€¢ æ¶µç›–ç†è®ºåŸºç¡€åˆ°å®žé™…åº”ç”¨
â€¢ æ—¶é—´è·¨åº¦åˆç†ï¼Œå…¼é¡¾ç»å…¸ä¸Žå‰æ²¿

ðŸ“– **æŽ¨èé˜…è¯»é¡ºåº**:
1. å…ˆè¯»ç»¼è¿°æ€§æ–‡çŒ®å»ºç«‹æ•´ä½“æ¡†æž¶
2. æ·±å…¥æ ¸å¿ƒç†è®ºå’Œæ–¹æ³•æ–‡çŒ®
3. äº†è§£æœ€æ–°åº”ç”¨å’Œå‘å±•è¶‹åŠ¿

ðŸ’¡ æç¤º: è¿™æ˜¯æ¼”ç¤ºæ¨¡å¼çš„åˆ†æžç»“æžœã€‚é…ç½®LLM APIå¯†é’¥åŽå¯èŽ·å¾—åŸºäºŽå†…å®¹çš„æ·±åº¦æ™ºèƒ½åˆ†æžã€‚"""
        
        elif analysis_type == "quality":
            return f"""â­ æ–‡çŒ®è´¨é‡åˆ†æž

ðŸ“Š **æ•´ä½“è´¨é‡è¯„ä¼°**:
â€¢ ä¼˜ç§€: {max(1, count//4)} ç¯‡ - å½±å“åŠ›é«˜ï¼Œæ–¹æ³•ä¸¥è°¨
â€¢ è‰¯å¥½: {max(1, count//2)} ç¯‡ - è´¨é‡å¯é ï¼Œè´¡çŒ®æ˜Žç¡®  
â€¢ ä¸€èˆ¬: {count - max(1, count//4) - max(1, count//2)} ç¯‡ - å‚è€ƒä»·å€¼æœ‰é™

ðŸ† **å½±å“åŠ›æŒ‡æ ‡**:
â€¢ å¹³å‡å¼•ç”¨æ¬¡æ•°è¾ƒé«˜
â€¢ å¤šæ•°å‘è¡¨åœ¨çŸ¥åæœŸåˆŠ/ä¼šè®®
â€¢ ä½œè€…å…·æœ‰è‰¯å¥½å­¦æœ¯å£°èª‰

ðŸ”¬ **ç ”ç©¶æ–¹æ³•**:
â€¢ ç†è®ºç ”ç©¶ä¸Žå®žè¯ç ”ç©¶å¹¶é‡
â€¢ æ–¹æ³•è®ºç›¸å¯¹æˆç†Ÿ
â€¢ æ•°æ®æ¥æºå¯é 

ðŸ’¡ å»ºè®®é‡ç‚¹å…³æ³¨é«˜è´¨é‡æ–‡çŒ®ï¼Œä½œä¸ºç ”ç©¶çš„ä¸»è¦å‚è€ƒä¾æ®ã€‚"""
            
        else:  # trend
            return f"""ðŸ“ˆ æ–‡çŒ®è¶‹åŠ¿åˆ†æž

ðŸ”„ **ç ”ç©¶å‘å±•è¶‹åŠ¿**:
â€¢ è¯¥é¢†åŸŸç ”ç©¶å‘ˆä¸Šå‡è¶‹åŠ¿
â€¢ è¿‘å¹´æ¥ç ”ç©¶çƒ­åº¦æŒç»­å¢žé•¿
â€¢ è·¨å­¦ç§‘èžåˆç‰¹å¾æ˜Žæ˜¾

ðŸŽ¯ **çƒ­ç‚¹æ–¹å‘**:
â€¢ ç†è®ºåˆ›æ–°ä¸Žæ–¹æ³•æ”¹è¿›
â€¢ å®žé™…åº”ç”¨åœºæ™¯æ‹“å±•  
â€¢ æŠ€æœ¯èžåˆä¸Žé›†æˆ

ðŸš€ **æœªæ¥å±•æœ›**:
â€¢ é¢„è®¡ç›¸å…³ç ”ç©¶å°†ç»§ç»­æ·±å…¥
â€¢ åº”ç”¨é¢†åŸŸæœ‰æœ›è¿›ä¸€æ­¥æ‰©å¤§
â€¢ è·¨é¢†åŸŸåˆä½œè¶‹åŠ¿æ˜Žæ˜¾

ðŸ’¡ è¿™äº›è¶‹åŠ¿åˆ†æžåŸºäºŽæ–‡çŒ®çš„æ—¶é—´åˆ†å¸ƒå’Œæ¥æºç‰¹å¾ã€‚é…ç½®LLM APIå¯†é’¥åŽå¯èŽ·å¾—åŸºäºŽå†…å®¹çš„æ·±åº¦è¶‹åŠ¿åˆ†æžã€‚"""
    
    def _generate_citation(self, literature_data: Dict[str, Any], style: str) -> str:
        """ç”Ÿæˆæ ‡å‡†æ ¼å¼å¼•ç”¨"""
        title = literature_data.get("title", "")
        authors = literature_data.get("authors", [])
        year = literature_data.get("year", "")
        doi = literature_data.get("doi", "")
        
        authors_str = ", ".join(authors[:3])
        if len(authors) > 3:
            authors_str += " et al."
        
        if style.upper() == "APA":
            citation = f"{authors_str} ({year}). {title}."
            if doi:
                citation += f" https://doi.org/{doi}"
        elif style.upper() == "MLA":
            citation = f"{authors_str}. \"{title}.\" {year}."
        elif style.upper() == "CHICAGO":
            citation = f"{authors_str}. \"{title}.\" Accessed {datetime.now().strftime('%B %d, %Y')}."
        else:
            citation = f"{authors_str} ({year}). {title}."
        
        return citation
    
    async def validate_citations(self, content: str) -> Dict[str, Any]:
        """éªŒè¯æ–‡æœ¬ä¸­çš„å¼•ç”¨"""
        try:
            # ç®€å•çš„å¼•ç”¨æå–å’ŒéªŒè¯
            import re
            
            # æå–å¼•ç”¨æ¨¡å¼: [1], [2], (Author, Year)
            numbered_citations = re.findall(r'\[(\d+)\]', content)
            author_year_citations = re.findall(r'\(([A-Za-z\s,]+),\s*(\d{4})\)', content)
            
            total_citations = len(numbered_citations) + len(author_year_citations)
            
            if total_citations == 0:
                return {
                    "success": True,
                    "valid": True,
                    "citation_count": 0,
                    "message": "No citations found"
                }
            
            # æ¨¡æ‹ŸéªŒè¯é€»è¾‘
            # åœ¨å®žé™…å®žçŽ°ä¸­ï¼Œè¿™é‡Œä¼šè°ƒç”¨CrossRef APIéªŒè¯DOI
            valid_citations = max(int(total_citations * 0.8), 1)  # å‡è®¾80%çš„å¼•ç”¨æœ‰æ•ˆ
            
            return {
                "success": True,
                "valid": valid_citations >= total_citations * 0.7,  # 70%çš„å¼•ç”¨æœ‰æ•ˆæ‰ç®—é€šè¿‡
                "citation_count": total_citations,
                "valid_count": valid_citations,
                "validation_rate": valid_citations / total_citations if total_citations > 0 else 0,
                "message": f"Found {total_citations} citations, {valid_citations} verified"
            }
            
        except Exception as e:
            return {
                "success": False,
                "valid": False,
                "citation_count": 0,
                "error": str(e)
            }